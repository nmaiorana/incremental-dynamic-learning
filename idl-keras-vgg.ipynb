{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incremental Dynamic Learning\n",
    "\n",
    "## Overview\n",
    "\n",
    "The idea behind Incremental Dynamic Learning networks is that information is not always learned at once, up front. As information is encountered, we train on the new data. Adding the new information to our existing knowlege base. Humans, are said to be able to recognize an image in 13 milliseconds after seeing it.The new image is added to their existing learned information and they do not have to retrain on all images they have ever seen.\n",
    "\n",
    "## Example\n",
    "\n",
    "As an example of how this can be used in the real world, I will use field biologists for my use case.\n",
    "\n",
    "Imagine a group of field biologists are in the field and all have a mobile application which allows them to photograph wildlife they encounter, label it and forward it to a central system. The central system takes in the new photographs and trains a neural network on each piece of new data that comes in. W/out having to retrain a new model based on all past photographs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1\n",
    "\n",
    "The experiment will consist of using a pre-trained network from TensorFlow (VGG) to generate our classification data. Our data will consist of using flower images provided with TensorFlow examples.\n",
    "\n",
    "Once the data has be converted by the VGG network, the process of training our network begins. This will be done by feeding the network 1 image at a time, allowing the network to train for a short duration (13ms) and then move onto the next image. A fixed validation set will be used to monitor progress as the images are fed one at a time to the network.\n",
    "\n",
    "The goal is to get an acceptable accuracy, similar to what a traditionally trained network would achieve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Construction\n",
    "\n",
    "The firs thing we will do is construct our networks. We will use 3 different network models for this experiment:\n",
    "* The Convolutional Network (VGG16) - Used to convolve our images\n",
    "* The Classification Network (Dence Network) - Used to validate our training\n",
    "* Full model network (Convolutional + Classification) - Used to train our Classification network.\n",
    "\n",
    "The full model will actually be made of of layers from the Convolutional network and the Classification network. It will perform the job of convolving the images and classifying them. This is the model we will use to train our network.\n",
    "\n",
    "These models are separated to allow the experiment to be run more efficiently and will be used for different functions thruout the experiment. By convolving our validation and test data up front, we will eliminate a good deal of redundent processing of the same data. This will allow us not to perform a validation step during each training epoch, and give us the flexibility of performing a validation step after some number of images are trained. Thus allowing us to monitor the progress of our work.\n",
    "\n",
    "One thing to note is that we will make all the VGG16 layers not trainable and we will not include the top layer (because we are providing our own classifier.) This will allow us to feed our images into the full model, but train only the classification layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.contrib.keras import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get sample data\n",
    "\n",
    "Let's pull down some sample data using photos of flowers provided by TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "dataset_folder_path = 'flower_photos'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile('flower_photos.tar.gz'):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='Flowers Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'http://download.tensorflow.org/example_images/flower_photos.tgz',\n",
    "            'flower_photos.tar.gz',\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(dataset_folder_path):\n",
    "    with tarfile.open('flower_photos.tar.gz') as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read a sample image to test our networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_dir = 'flower_photos/'\n",
    "\n",
    "test_img = preprocessing.image.load_img(data_dir + 'sunflowers/6953297_8576bf4ea3.jpg', target_size=(224,224,3))\n",
    "test_img = preprocessing.image.img_to_array(test_img)\n",
    "test_img = test_img.astype(np.uint8) \n",
    "\n",
    "print ('Image shape: {}'.format(test_img.shape))\n",
    "plt.imshow(test_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.keras import models\n",
    "from tensorflow.contrib.keras import layers\n",
    "from tensorflow.contrib.keras import optimizers\n",
    "from tensorflow.contrib.keras import applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_conv_model(input_shape=(224,224,3), summary=False):\n",
    "\n",
    "    model = applications.vgg16.VGG16(include_top=False, weights='imagenet', input_shape=input_shape, pooling='avg')\n",
    "\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    if summary:\n",
    "        model.summary()\n",
    "    return model\n",
    "\n",
    "conv_model = build_conv_model(summary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the conv model to convolve the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv_model = build_conv_model()\n",
    "feed_image = np.expand_dims(test_img, axis=0)\n",
    "convolved_img = conv_model.predict(feed_image)\n",
    "\n",
    "print ('Convolved image shape: {}'.format(convolved_img.shape))\n",
    "\n",
    "conv_out_layer = conv_model.layers[-1]\n",
    "\n",
    "print ('Shape of output layer is {}'.format(conv_out_layer.get_output_at(0).get_shape()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Network\n",
    "\n",
    "Here we are free to experiment with various dense layers and configurations. I have found initializing both the weights and the biases to zero produces good resluts. Also a low learning rate worked very well in producing more accurate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_classifcation_model(conv_model, learning_rate=0.0001, classes=5, summary=False):\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    input_shape = conv_model.layers[-1].output_shape[1]\n",
    "    model.add(layers.Dense(256, input_shape=[input_shape]))\n",
    "    model.add(layers.Dense(classes, \n",
    "                           kernel_initializer='zeros', \n",
    "                           bias_initializer='zeros'))\n",
    "\n",
    "    model.add(layers.Activation('softmax', name='out'))\n",
    "    optimizer = optimizers.Adam(lr=learning_rate)\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    if summary:\n",
    "        model.summary()\n",
    "    return model\n",
    "\n",
    "conv_model = build_conv_model()\n",
    "classification_model = build_classifcation_model(conv_model, summary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the classification model to train on an convolved image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv_model = build_conv_model()\n",
    "classification_model = build_classifcation_model(conv_model)\n",
    "feed_image = np.expand_dims(test_img, axis=0)\n",
    "convolved_img = conv_model.predict(feed_image)\n",
    "label = [0, 0, 0, 1, 0]\n",
    "label = np.expand_dims(label, axis=0)\n",
    "classification_model.fit(convolved_img, label, epochs=1)\n",
    "\n",
    "pred = classification_model.predict_classes(convolved_img)\n",
    "print ('prediction is {}'.format(pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct full network using layers from conv and classifcation models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_full_model(conv_model, classification_model, learning_rate=0.0001, summary=False):\n",
    "    # Allocate pre-built model and make non-trainable\n",
    "    model = models.Sequential()\n",
    "    for layer in conv_model.layers:\n",
    "        model.add(layer)\n",
    "    \n",
    "    for layer in classification_model.layers:\n",
    "        model.add(layer)\n",
    "    \n",
    "    optimizer = optimizers.Adam(lr=learning_rate)\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    if summary:\n",
    "        model.summary()\n",
    "    return model\n",
    "\n",
    "conv_model = build_conv_model()\n",
    "classification_model = build_classifcation_model(conv_model)\n",
    "full_model = build_full_model(conv_model, classification_model, summary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the full model on the original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv_model = build_conv_model()\n",
    "classification_model = build_classifcation_model(conv_model)\n",
    "full_model = build_full_model(conv_model, classification_model)\n",
    "feed_image = np.expand_dims(test_img, axis=0)\n",
    "label = [0, 0, 0, 1, 0]\n",
    "label = np.expand_dims(label, axis=0)\n",
    "full_model.fit(feed_image, label, epochs=1)\n",
    "\n",
    "pred = full_model.predict_classes(feed_image)\n",
    "print ('full prediction is {}'.format(pred))\n",
    "\n",
    "# Demonstrate the classification model was also trained\n",
    "convolved_img = conv_model.predict(feed_image)\n",
    "pred = classification_model.predict_classes(convolved_img)\n",
    "print ('classification prediction is {}'.format(pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read all the images, reshape the images and create labels for them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.keras import preprocessing\n",
    "\n",
    "data_dir = 'flower_photos/'\n",
    "contents = os.listdir(data_dir)\n",
    "classes = [each for each in contents if os.path.isdir(data_dir + each)]\n",
    "\n",
    "# Set the batch size higher if you can fit in in your GPU memory\n",
    "images = []\n",
    "labels = []\n",
    "batch = []\n",
    "\n",
    "for each in classes:\n",
    "    print(\"Starting {} images\".format(each))\n",
    "    class_path = data_dir + each\n",
    "    files = os.listdir(class_path)\n",
    "    for ii, file in enumerate(files, 1):\n",
    "        # Add images to the current batch\n",
    "        # utils.load_image crops the input images for us, from the center\n",
    "        img = preprocessing.image.load_img(os.path.join(class_path, file), target_size=(224,224,3))\n",
    "        img = preprocessing.image.img_to_array(img)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        img = img.astype(np.uint8) \n",
    "        images.append(img)\n",
    "        labels.append(each)\n",
    "\n",
    "        # Display progress\n",
    "        if ii % 250 == 0 or ii == len(files):\n",
    "            print('{} images processed'.format(ii))\n",
    "            \n",
    "images = np.concatenate(images)\n",
    "\n",
    "print ('Image loading complete: {}'.format(images.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(labels)\n",
    "\n",
    "labels_vecs = lb.transform(labels)\n",
    "print (labels_vecs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the training, validation and test data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import  train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels_vecs, train_size=0.8, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_image = X_train[1000]\n",
    "sample_label = y_train[1000]\n",
    "print (sample_label)\n",
    "print (classes[np.argmax(sample_label)])\n",
    "plt.imshow(sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datagen = preprocessing.image.ImageDataGenerator(\n",
    "        rotation_range=5,\n",
    "        width_shift_range=0.01,\n",
    "        height_shift_range=0.01,\n",
    "        shear_range = 0.01,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=False,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "def gen_batch(image, label, count=9):\n",
    "    batch_data = []\n",
    "    batch_lables = []\n",
    "    batch_data.append(image)\n",
    "    batch_lables.append(label.tolist())\n",
    "    for X_batch in datagen.flow(x=image):\n",
    "        gen_image = X_batch[0]\n",
    "        gen_image = gen_image.reshape((1,) + gen_image.shape)\n",
    "        gen_image = gen_image.astype(np.uint8) \n",
    "        batch_data.append(gen_image)\n",
    "        batch_lables.append(label.tolist())\n",
    "        if len(batch_data) > count - 1:\n",
    "            return batch_data, batch_lables\n",
    "        \n",
    "batch_images, batch_labels = gen_batch(first_image, first_label, count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(first_label)\n",
    "plt.imshow(first_image[0])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "batch_images, batch_labels = gen_batch(first_image, first_label, count=9)\n",
    "i = 0\n",
    "print (batch_labels)\n",
    "for image, label in zip(batch_images, batch_labels):\n",
    "    plt.subplot(330 + 1 + i)\n",
    "    print (label)\n",
    "    plt.imshow(image[0])\n",
    "    i += 1\n",
    "    \n",
    "# show the plot    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.keras import applications\n",
    "\n",
    "model = applications.vgg16.VGG16(include_top=False, weights='imagenet', input_shape=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.keras import models\n",
    "from tensorflow.contrib.keras import layers\n",
    "from tensorflow.contrib.keras import optimizers\n",
    "from tensorflow.contrib.keras import applications\n",
    "\n",
    "def build_flower_classifcation_model(learning_rate=0.001, classes=5):\n",
    "    # Allocate pre-built model and make non-trainable\n",
    "    model = models.Sequential()\n",
    "    vgg = applications.vgg16.VGG16(include_top=False, weights='imagenet', classes=classes, input_shape=(224, 224, 3))\n",
    "    for layer in vgg.layers:\n",
    "        trainable = False\n",
    "        layer.trainable = trainable\n",
    "        model.add(layer)\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(256))\n",
    "    model.add(layers.Dropout(.5))\n",
    "    model.add(layers.Dense(classes, kernel_initializer='zeros', bias_initializer='zeros'))\n",
    "\n",
    "    model.add(layers.Activation('softmax', name='out'))\n",
    "    optimizer = optimizers.Adam(lr=learning_rate)\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "model = build_flower_classifcation_model(learning_rate=0.0001, classes=len(labels_vecs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for index in range(len(X_train)):\n",
    "    single_image = X_train[index]\n",
    "    single_label = y_train[index]\n",
    "    batch_images, batch_labels = gen_batch(single_image, single_label, count=9)\n",
    "    print (batch_labels)\n",
    "    if index % 1 == 0:\n",
    "        verbose = True\n",
    "    else:\n",
    "        verbose = False\n",
    "    \n",
    "    print ('Image: ', index)\n",
    "    batch_images = np.concatenate(batch_images)\n",
    "    batch_val_images = np.concatenate(X_val)\n",
    "    model.fit(batch_images, batch_labels, validation_data=(batch_val_images, y_val), batch_size=len(batch_images), epochs=1, verbose=verbose)\n",
    "\n",
    "batch_text = np.concatenate(X_test)\n",
    "print (model.evaluate(batch_text, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "this_train = np.concatenate(X_train)\n",
    "print (this_train.shape)\n",
    "print (y_train.shape)\n",
    "#model.fit(this_train, y_train, validation_data=(X_val, y_val), batch_size=8, epochs=1, verbose=verbose)\n",
    "model.fit(this_train, y_train, batch_size=8, epochs=1, verbose=verbose)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
